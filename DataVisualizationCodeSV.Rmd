---
title: "DataVisualizationCodeSV"
author: "Saulai Vue"
date: "2025-05-15"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(tidyverse)
library(rvest) #web scraping package and working with html
library(tidytext) #converts text into tidy format, and text mining
library(httr)    #sends http requests and working with web API
library(stringr) #working with strings into tidyverse and cleaning text strings
library(readr)
library(ggplot2)
library(gganimate)
```


## Import Main Data Frame

```{r}
lyrics_final_df_url <- "https://raw.githubusercontent.com/vsaulai/STAT-345-FinalProject-Lyrics/refs/heads/main/final_lyrics_df.csv"
lyrics_df <- read.csv(lyrics_final_df_url)
View(lyrics_df)
```

## Function to Remove all NA values in Lyrics

```{r}
delete_na_rows <- function(df, column_name) {
  # Check if the column exists
  if (!column_name %in% names(df)) {
    stop("The specified column does not exist in the data frame.")
  }
  
  # Remove rows where the specified column is NA or blank
  df_clean <- df[!is.na(df[[column_name]]) & df[[column_name]] != "", ]
  
  return(df_clean)
}
```

## Run Previous Function

```{r}
lyrics_df_remove_na <- delete_na_rows(lyrics_df, "lyrics")

```

## Remove Unnecessary Columns
- Eventually, adding the row sums of total words estimated by udpipe model and finding the proportion of parts of speech.
- Therefore, removing all non words that showed up in the data count to get the total.

```{r}
lyrics_df_count <- lyrics_df_remove_na[ , !(names(lyrics_df_remove_na) %in% c("url", "other", "symbol", "numeral"))]

```


## Word Count from Udpipe Language Model

```{r}
lyrics_df_count <- lyrics_df_count %>%
  mutate(row_total = rowSums(.[ , 9:23], na.rm = TRUE))
lyrics_df_count <- lyrics_df_count %>%
  rename(pos_total = row_total)
```


## Average Word Count List (Floating Point)

```{r}
yearly_averages <- lyrics_df_count %>%
  group_by(Year) %>%
  summarize(
    avg_title_count = mean(title_repetition_count, na.rm = TRUE),
    avg_word_count = mean(word_count, na.rm = TRUE),
    avg_adjective = mean(adjective, na.rm = TRUE),
    avg_adposition = mean(adposition, na.rm = TRUE),
    avg_adverb = mean(adverb, na.rm = TRUE),
    avg_auxiliary_verb = mean(AUX, na.rm = TRUE),
    avg_coordinating_conj = mean(coordinating_conj, na.rm = TRUE),
    avg_determiner = mean(determiner, na.rm = TRUE),
    avg_interjection = mean(interjection, na.rm = TRUE),
    avg_noun = mean(noun, na.rm = TRUE),
    avg_particle = mean(particle, na.rm = TRUE),
    avg_pronoun = mean(pronoun, na.rm = TRUE),
    avg_proper_noun = mean(proper_noun, na.rm = TRUE),
    avg_verb = mean(verb, na.rm = TRUE),
    avg_punctuation = mean(punctuation, na.rm = TRUE),
    avg_subordinating_conj = mean(subordinating_conj, na.rm = TRUE),
    avg_NA = mean(`NA.`, na.rm = TRUE),
    avg_pos_total = mean(pos_total, na.rm = TRUE),
    .groups = 'drop'
  )

```


## Average Word Count List (Rounded up to Two Decimal Points)

```{r}
yearly_averages_rounded <- lyrics_df_count %>%
  group_by(Year) %>%
  summarize(
    avg_title_count = round(mean(title_repetition_count, na.rm = TRUE), 2),
    avg_word_count = round(mean(word_count, na.rm = TRUE), 2),
    avg_adjective = round(mean(adjective, na.rm = TRUE), 2),
    avg_adposition = round(mean(adposition, na.rm = TRUE), 2),
    avg_adverb = round(mean(adverb, na.rm = TRUE), 2),
    avg_auxiliary_verb = round(mean(AUX, na.rm = TRUE), 2),
    avg_coordinating_conj = round(mean(coordinating_conj, na.rm = TRUE), 2),
    avg_determiner = round(mean(determiner, na.rm = TRUE), 2),
    avg_interjection = round(mean(interjection, na.rm = TRUE), 2),
    avg_noun = round(mean(noun, na.rm = TRUE), 2),
    avg_particle = round(mean(particle, na.rm = TRUE), 2),
    avg_pronoun = round(mean(pronoun, na.rm = TRUE), 2),
    avg_proper_noun = round(mean(proper_noun, na.rm = TRUE), 2),
    avg_verb = round(mean(verb, na.rm = TRUE), 2),
    avg_punctuation = round(mean(punctuation, na.rm = TRUE), 2),
    avg_subordinating_conj = round(mean(subordinating_conj, na.rm = TRUE), 2),
    avg_NA = round(mean(`NA.`, na.rm = TRUE), 2),
    avg_pos_total = round(mean(pos_total, na.rm = TRUE), 2),
    .groups = 'drop'
  )
```



```{r}
combined_averages <- list()

# Loop over the names (e.g., years) in the lists
for (Year in names(yearly_averages)) {
  combined_averages[[Year]] <- list(
    unrounded = yearly_averages[[Year]],
    rounded = yearly_averages_rounded[[Year]]
  )
}

```


## Splitting into Periods by Decades into A List

1958-1969, 1970-1979, 1980-1989, 1990-1999, 2000-2009, 2010-2019, 2020-2024.

```{r}
# Create a list of named intervals
year_intervals <- list(
  "1958_1969" = c(1958, 1969),
  "1970_1979" = c(1970, 1979),
  "1980_1989" = c(1980, 1989),
  "1990_1999" = c(1990, 1999),
  "2000_2009" = c(2000, 2009),
  "2010_2019" = c(2010, 2019),
  "2020_2024" = c(2020, 2024)
)

# Create a list to hold the split data frames
split_years <- list()

# For Loop to Split Years into Desired intervals
for (name in names(year_intervals)) {
  range <- year_intervals[[name]]
  start <- range[1]
  end <- range[2]
  
  # Filter the data for this range
  df_range <- subset(lyrics_df_count, Year >= start & Year <= end)
  
  # Save to environment and list
  assign(paste0("lyrics_", name), df_range, envir = .GlobalEnv)
  split_years[[paste0("lyrics_", name)]] <- df_range
}

```

## Splitting POS types into categories


```{r}
# 1958–1969
ratio_1958_1969 <- lyrics_1958_1969 %>% # Taking the proportion of each song's POS type to total POS word for each year
  mutate(
    nouns_group = noun / pos_total,
    proper_nouns_group = proper_noun / pos_total, # Proper Nouns are significant because it's naming a direct person, place, or thing. Which may hint towards a decade's cultural reference.
    verbs_group = (verb + AUX )/ pos_total, # Verbs + Auxiliary Verbs were my preference of POS category, Actions are significant POS word types.
    adjectives_group = adjective / pos_total, # Adjectives are descriptive POS and are significant to stand alone 
    adverbs_group = adverb / pos_total + particle / pos_total, # Adverbs are describing actions and may have an argument to be in verbs but I chose to leave it separated. Also contains particles which are of the same function like adverbs i.e. ("up", "on", "out", I ran "into" my professor)
    pronouns_group = pronoun / pos_total, # Pronouns operate like proper nouns, Hinting at specifically someone i.e.(Him, Her, They, It, He, She, etc.) could be referencing an Ex boyfriend or girlfriend. So, I thought this to be significant to stand out.
    interjections_group = interjection / pos_total, # Interjections are emotional words like "Hurray!", "Hey", "Ow", they can oftentimes be related to slang which I though significant
    punctuation_group = punctuation / pos_total, # Punctuation may not seem relevant but it is sometimes indicating slang or 'double' words like can't, shouldn't, Ain't, etc. Slang words are pretty significant.
    # Function Word Group is everything else: determiners ("a", "an", "the"); conjunctions("for", "and", "but", "whereas", "unless"); 
    #  `NA.` is other words that the language model did not comprehend what POS type the word was.
    function_word_group = (determiner + coordinating_conj + subordinating_conj + adposition + `NA.`) / pos_total,
  ) %>%
  summarise( # Combining each song to each decade category and repeat for each decade interval
    decade = "1958–1969",
    nouns = mean(nouns_group, na.rm = TRUE),
    proper_nouns = mean(proper_nouns_group, na.rm = TRUE),
    verbs = mean(verbs_group, na.rm = TRUE),
    adjectives = mean(adjectives_group, na.rm = TRUE),
    adverbs = mean(adverbs_group, na.rm = TRUE),
    pronouns = mean(pronouns_group, na.rm = TRUE),
    interjections = mean(interjections_group, na.rm = TRUE),
    punctuation = mean(punctuation_group, na.rm = TRUE),
    function_words = mean(function_word_group, na.rm = TRUE)
  ) 
# 1970-1979
ratio_1970_1979 <- lyrics_1970_1979 %>%
  mutate( 
    nouns_group = noun / pos_total,
    proper_nouns_group = proper_noun / pos_total,
    verbs_group = (verb + AUX )/ pos_total,
    adjectives_group = adjective / pos_total,
    adverbs_group = adverb / pos_total + particle / pos_total,
    pronouns_group = pronoun / pos_total,
    interjections_group = interjection / pos_total,
    punctuation_group = punctuation / pos_total,
    function_word_group = (determiner + coordinating_conj + subordinating_conj + adposition + `NA.`) / pos_total,
  ) %>%
  summarise(
    decade = "1970-1979",
    nouns = mean(nouns_group, na.rm = TRUE),
    proper_nouns = mean(proper_nouns_group, na.rm = TRUE),
    verbs = mean(verbs_group, na.rm = TRUE),
    adjectives = mean(adjectives_group, na.rm = TRUE),
    adverbs = mean(adverbs_group, na.rm = TRUE),
    pronouns = mean(pronouns_group, na.rm = TRUE),
    interjections = mean(interjections_group, na.rm = TRUE),
    punctuation = mean(punctuation_group, na.rm = TRUE),
    function_words = mean(function_word_group, na.rm = TRUE)
  )
# 1980-1989
ratio_1980_1989 <- lyrics_1980_1989 %>%
  mutate(
    nouns_group = noun / pos_total,
    proper_nouns_group = proper_noun / pos_total,
    verbs_group = (verb + AUX )/ pos_total,
    adjectives_group = adjective / pos_total,
    adverbs_group = adverb / pos_total + particle / pos_total,
    pronouns_group = pronoun / pos_total,
    interjections_group = interjection / pos_total,
    punctuation_group = punctuation / pos_total,
    function_word_group = (determiner + coordinating_conj + subordinating_conj + adposition + `NA.`) / pos_total,
  ) %>%
  summarise(
    decade = "1980-1989",
    nouns = mean(nouns_group, na.rm = TRUE),
    proper_nouns = mean(proper_nouns_group, na.rm = TRUE),
    verbs = mean(verbs_group, na.rm = TRUE),
    adjectives = mean(adjectives_group, na.rm = TRUE),
    adverbs = mean(adverbs_group, na.rm = TRUE),
    pronouns = mean(pronouns_group, na.rm = TRUE),
    interjections = mean(interjections_group, na.rm = TRUE),
    punctuation = mean(punctuation_group, na.rm = TRUE),
    function_words = mean(function_word_group, na.rm = TRUE)
  )
# 1990-1999
ratio_1990_1999 <- lyrics_1990_1999 %>%
  mutate(
    nouns_group = noun / pos_total,
    proper_nouns_group = proper_noun / pos_total,
    verbs_group = (verb + AUX )/ pos_total,
    adjectives_group = adjective / pos_total,
    adverbs_group = adverb / pos_total + particle / pos_total,
    pronouns_group = pronoun / pos_total,
    interjections_group = interjection / pos_total,
    punctuation_group = punctuation / pos_total,
    function_word_group = (determiner + coordinating_conj + subordinating_conj + adposition + `NA.`) / pos_total,
  ) %>%
  summarise(
    decade = "1990-1999",
    nouns = mean(nouns_group, na.rm = TRUE),
    proper_nouns = mean(proper_nouns_group, na.rm = TRUE),
    verbs = mean(verbs_group, na.rm = TRUE),
    adjectives = mean(adjectives_group, na.rm = TRUE),
    adverbs = mean(adverbs_group, na.rm = TRUE),
    pronouns = mean(pronouns_group, na.rm = TRUE),
    interjections = mean(interjections_group, na.rm = TRUE),
    punctuation = mean(punctuation_group, na.rm = TRUE),
    function_words = mean(function_word_group, na.rm = TRUE)
  )
# 2000–2009
ratio_2000_2009 <- lyrics_2000_2009 %>%
  mutate(
    nouns_group = noun / pos_total,
    proper_nouns_group = proper_noun / pos_total,
    verbs_group = (verb + AUX )/ pos_total,
    adjectives_group = adjective / pos_total,
    adverbs_group = adverb / pos_total + particle / pos_total,
    pronouns_group = pronoun / pos_total,
    interjections_group = interjection / pos_total,
    punctuation_group = punctuation / pos_total,
    function_word_group = (determiner + coordinating_conj + subordinating_conj + adposition + `NA.`) / pos_total,
  ) %>%
  summarise(
    decade = "2000–2009",
    nouns = mean(nouns_group, na.rm = TRUE),
    proper_nouns = mean(proper_nouns_group, na.rm = TRUE),
    verbs = mean(verbs_group, na.rm = TRUE),
    adjectives = mean(adjectives_group, na.rm = TRUE),
    adverbs = mean(adverbs_group, na.rm = TRUE),
    pronouns = mean(pronouns_group, na.rm = TRUE),
    interjections = mean(interjections_group, na.rm = TRUE),
    punctuation = mean(punctuation_group, na.rm = TRUE),
    function_words = mean(function_word_group, na.rm = TRUE)
  )
# 2010–2019
ratio_2010_2019 <- lyrics_2010_2019 %>%
  mutate(
    nouns_group = noun / pos_total,
    proper_nouns_group = proper_noun / pos_total,
    verbs_group = (verb + AUX )/ pos_total,
    adjectives_group = adjective / pos_total,
    adverbs_group = adverb / pos_total + particle / pos_total,
    pronouns_group = pronoun / pos_total,
    interjections_group = interjection / pos_total,
    punctuation_group = punctuation / pos_total,
    function_word_group = (determiner + coordinating_conj + subordinating_conj + adposition + `NA.`) / pos_total,
  ) %>%
  summarise(
    decade = "2010–2019",
    nouns = mean(nouns_group, na.rm = TRUE),
    proper_nouns = mean(proper_nouns_group, na.rm = TRUE),
    verbs = mean(verbs_group, na.rm = TRUE),
    adjectives = mean(adjectives_group, na.rm = TRUE),
    adverbs = mean(adverbs_group, na.rm = TRUE),
    pronouns = mean(pronouns_group, na.rm = TRUE),
    interjections = mean(interjections_group, na.rm = TRUE),
    punctuation = mean(punctuation_group, na.rm = TRUE),
    function_words = mean(function_word_group, na.rm = TRUE)
  )
# 2020–2024
ratio_2020_24 <- lyrics_2020_2024 %>%
  mutate(
    nouns_group = noun / pos_total,
    proper_nouns_group = proper_noun / pos_total,
    verbs_group = (verb + AUX )/ pos_total,
    adjectives_group = adjective / pos_total,
    adverbs_group = adverb / pos_total + particle / pos_total,
    pronouns_group = pronoun / pos_total,
    interjections_group = interjection / pos_total,
    punctuation_group = punctuation / pos_total,
    function_word_group = (determiner + coordinating_conj + subordinating_conj + adposition + `NA.`) / pos_total,
  ) %>%
  summarise(
    decade = "2020–2024",
    nouns = mean(nouns_group, na.rm = TRUE),
    proper_nouns = mean(proper_nouns_group, na.rm = TRUE),
    verbs = mean(verbs_group, na.rm = TRUE),
    adjectives = mean(adjectives_group, na.rm = TRUE),
    adverbs = mean(adverbs_group, na.rm = TRUE),
    pronouns = mean(pronouns_group, na.rm = TRUE),
    interjections = mean(interjections_group, na.rm = TRUE),
    punctuation = mean(punctuation_group, na.rm = TRUE),
    function_words = mean(function_word_group, na.rm = TRUE)
  )

```



```{r}
View(lyrics_1958_1969)
View(lyrics_1970_1979)
View(lyrics_1980_1989)
View(lyrics_1990_1999)
View(lyrics_2000_2009)
View(lyrics_2010_2019)
View(lyrics_2020_2024)
View(yearly_averages)
View(yearly_averages_rounded)
```

## Average Amount of Words Count per Year(Top 20 Billboard Songs)

- Takes every Top 17-20 Billboard Songs Per Year,

```{r}
wordcount_by_year <- bind_rows(yearly_averages)

ggplot(wordcount_by_year, aes(x = as.numeric(Year), y = avg_word_count)) +
  geom_line(color = "steelblue", size = 1) +
  geom_point(color = "red", size = 1.5) +
  geom_smooth(method = "lm", color = "darkgreen", linetype = "dashed", se = TRUE) +
  labs(
    title = "Average Word Count per Year (Top 20 Billboard Songs)",
    x = "Year (1958-2024)",
    y = "Average Word Count"
  ) +
  theme_minimal()

```

```{r}
noun_by_year <- bind_rows(yearly_averages)

ggplot(wordcount_by_year, aes(x = as.numeric(Year), y = avg_noun + avg_proper_noun)) +
  geom_line(color = "steelblue", size = 1) +
  geom_point(color = "darkred", size = 1.5) +
  geom_smooth(method = "lm", color = "black", linetype = "dashed", se = TRUE) +
  labs(
    title = "Average Nouns in Lyrics per Year (Top 20 Billboard Songs)",
    x = "Year (1958-2024)",
    y = "Average Noun Count"
  ) +
  theme_minimal()

```

```{r}
df_sample <- data.frame(
  year = rep(2000:2002, each = 4),
  pos = rep(c("noun", "verb", "adj", "adv"), 3),
  count = c(100, 80, 60, 40, 120, 90, 70, 30, 130, 95, 65, 50)
)

```


```{r}
# Create a dataframe with proportions
df_sample <- df_sample %>%
  group_by(year) %>%
  mutate(percentage = count / sum(count) * 100)

# Create pie chart using bar chart + coord_polar
p <- ggplot(df_sample, aes(x = "", y = percentage, fill = pos)) +
  geom_bar(stat = "identity", width = 1, color = "white") +
  coord_polar("y", start = 0) +
  theme_void() + 
  theme(legend.position = "right") +
  labs(title = "POS Distribution in {closest_state}", fill = "Part of Speech") +
  transition_states(year, transition_length = 2, state_length = 1) +
  ease_aes("cubic-in-out")

# Animate
animate(p, width = 600, height = 600, fps = 10, duration = 10)
```


```{r}
# Suppose df_lyrics has year and pos counts
df_long <- yearly_averages %>%
  select(year, noun_count, verb_count, adj_count, adv_count) %>%
  pivot_longer(cols = -year, names_to = "pos", values_to = "count") %>%
  mutate(pos = gsub("_count", "", pos))
```


```{r}

df_long <- df %>%
  pivot_longer(
    cols = c(nouns, verbs, adjectives, adverbs, interjections),
    names_to = "pos",
    values_to = "count"
  ) %>%
  mutate(percentage = count / total_words * 100)

```







----------------------





```{r}
df <- lyrics_1958_1969 %>%
  mutate(row_total = rowSums(across(c(math, english))))

```

```{r}

```

```{r}

```

